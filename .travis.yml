sudo: required
services:
    - docker

env:
    global:
        # Get the latest git commit SHA and store as a variable we ca acces
        - GIT_SHA=$(git rev-parse HEAD)
        # Force the Google cloud SDK to supress prompts
        - CLOUDSDK_CORE_DISABLE_PROMPTS=1

before_install:
    # Decrypt the JSON file we uploaded using the Travis CLI
    # This will create a file called service-account.json
    # Make sure the -out name matches the one in the gcloud command below
    # Commenting out since we shut down our GCP cluster
    #- openssl aes-256-cbc -K $encrypted_9f3b5599b056_key -iv $encrypted_9f3b5599b056_iv -in service-account.json.enc -out service-account.json -d
    # This is the new one
    # This must be replaced any time you create a new cluster
    #- openssl aes-256-cbc -K $encrypted_0c35eebf403c_key -iv $encrypted_0c35eebf403c_iv -in service-account.json.enc -out service-account.json -d
    # Install the Google Cloud SDK
    # Commenting out since we shut down our GCP cluster
    #- curl https://sdk.cloud.google.com | bash > /dev/null;
    # Source this file
    # Commenting out since we shut down our GCP cluster
    #- source $HOME/google-cloud-sdk/path.bash.inc
    # Install the kubectl CLI
    # Commenting out since we shut down our GCP cluster
    #- gcloud components update kubectl
    # Authorize with Google Cloud via the service account - same as AWS IAM
    # Make sure the key file is the same name as the -out one in the first step above
    # Commenting out since we shut down our GCP cluster
    #- gcloud auth activate-service-account --key-file service-account.json
    # Tell GCP which project and location/region
    # This is NOT your project name, is the ID
    # Commenting out since we shut down our GCP cluster
    # This must be updated any time you create a new cluster
    #- gcloud config set project multi-docker-k8s-276920
    # Click on Nav menu then Kubernetes Engine to get the Location
    # Commenting out since we shut down our GCP cluster
    #- gcloud config set compute/zone us-east1-b
    # Tell it which cluster to work with
    # Get this from the Name on the Kubernetes Engine page
    # Commenting out since we shut down our GCP cluster
    #- gcloud container clusters get-credentials multi-cluster
    # Log in to the docker CLI using creds stored as vars in Travis CI 
    - echo "$DOCKER_PASSWORD" | docker login -u "$DOCKER_ID" --password-stdin
    # Build our image and run the tests - the react-test is a made up name
    # You can use anything you want - you just have to match it below to run the test
    - docker build -t mikenol/react-test -f ./client/Dockerfile.dev ./client

script:
    # This is using the made up image name we build above
    #- docker run -e CI=true mikenol/react-test npm test
    # Not sure if we actually need this or not, will see what happens
    - docker run -e CI=true mikenol/react-test npm test -- --coverage

language: generic

deploy:
    provider: script
    script: bash ./deploy.sh
    # Only do this when we are messing with the master branch
    on:
        branch: master

# This was used for AWS, leaving it in just cause...
#after_success:
#    # Build all of our images
#    - docker build -t mikenol/multi-client ./client
#    - docker build -t mikenol/multi-nginx ./nginx
#    - docker build -t mikenol/multi-server ./server
#    - docker build -t mikenol/multi-worker ./worker
#
#    # Push images to docker hub
#    - docker push mikenol/multi-client
#    - docker push mikenol/multi-nginx
#    - docker push mikenol/multi-server
#    - docker push mikenol/multi-worker
#
#    - kubectl apply -f k8s

# This was for AWS and used in the complex-elastic-beanstalk project
# We are using GCP so this isn't used
# Leaving it in here anyway
#deploy:
#    # Only use if you are getting a missing bucket_name error
#    # edge: true
#    provider: elasticbeanstalk
#    region: "us-east-2"
#    app: "multi-docker"
#    env: "MultiDocker-env"
#    # Get this from S3 service in AWS for your region
#    bucket_name: "elasticbeanstalk-us-east-2-002528515977"
#    # This is made up
#    bucket_path: "docker-multi"
#    # Only do this when we are messing with the master branch
#    on:
#        branch: master
#    access_key_id: "$AWS_ACCESS_KEY"
#    # This does not work
#    #secret_access_key:
#    #    secure: "$AWS_SECRET_KEY"
#    secret_access_key: "$AWS_SECRET_KEY"
